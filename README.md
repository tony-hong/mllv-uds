# Seminar: Machine Learning for Language and Vision

## News

**May 9, 2023.** Our grading standard is online. 

**Apr 26, 2023.** Our tentative schedule is online. Please contact us ASAP if you have any questions.

**Apr 17, 2023.** Our kickoff meeting is scheduled for **April 18, 2023, from 12:15 to 13:45, at C7 3 - Seminarraum 1.12**. As the demand for attendance is exceedingly high, we have added more papers to our list. We kindly request that you attend the first two meetings to secure your spot. In the event that you are unable to attend but would still like to participate, please send us an email and we will arrange remote attendance for you. 

**Mar 27, 2023.** If you are interested, please send [Xudong Hong](mailto:xhong@coli.uni-saarland.de) an email to register for this seminar.

## Schedule

| Date          | Topic                               | Paper Title                                                                                   | Presenter                 |
|---------------|-------------------------------------|-----------------------------------------------------------------------------------------------|---------------------------|
| May 9, 2023   | Contrastive Pre-training - Image    | [Learning transferable visual models from natural language supervision](http://proceedings.mlr.press/v139/radford21a)                  | Raj Mohan Tumarada        |
| May 9, 2023   | Contrastive Pre-training - Image    | [Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation](https://proceedings.mlr.press/v162/li22n.html) | Larisa Ivanova                         |
| May 16, 2023  | Seq2seq Pre-training - Image        | [Simple Visual Language Model Pretraining with Weak Supervision](https://openreview.net/forum?id=GUrhfTuf_3)                             | Julian Schlenker          |
| May 16, 2023  | Seq2seq Pre-training - Image        | [Flava: A foundational language and vision alignment model](https://openaccess.thecvf.com/content/CVPR2022/html/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.html) | Mehrad Zamani             |
| May 23, 2023  | Pre-training - Video                | [Merlot: Multimodal neural script knowledge models](https://proceedings.neurips.cc/paper/2021/hash/c6d4eb15f1e84a36eff58eca3627c82e-Abstract.html)          | Yage Zhang             |
| May 23, 2023  | Pre-training - Video                | [Merlot reserve: Neural script knowledge through vision and language and sound](http://openaccess.thecvf.com/content/CVPR2022/html/Zellers_MERLOT_Reserve_Neural_Script_Knowledge_Through_Vision_and_Language_and_CVPR_2022_paper.html) | - |
| May 30, 2023  | Multitask Learning                  | [Unifying Vision-and-Language Tasks via Text Generation](https://proceedings.mlr.press/v139/cho21a.html)                              | Nitish Juttu   |
| May 30, 2023  | Multitask Learning                  | [Unit: Multimodal multitask learning with a unified transformer](https://openaccess.thecvf.com/content/ICCV2021/html/Hu_UniT_Multimodal_Multitask_Learning_With_a_Unified_Transformer_ICCV_2021_paper.html?ref=https://githubhelp.com) | Zixuan Liu                |
| June 6, 2023  | Multitask Learning                  | [Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework](https://proceedings.mlr.press/v162/wang22al.html) | Jakob Gürtler             |
| June 6, 2023  | Parameter Efficiency - Prompting    | [An empirical study of gpt-3 for few-shot knowledge-based vqa](https://ojs.aaai.org/index.php/AAAI/article/download/20215/19974)                   | Raphael Maximilian Stephan Maser |
| June 13, 2023 | Parameter Efficiency - Prompting    | [Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language](https://openreview.net/forum?id=G2Q2Mh3avow) | Karen Li                  |
| June 13, 2023 | Parameter Efficiency - Prompt Tuning | [Multimodal few-shot learning with frozen language models](https://proceedings.neurips.cc/paper/2021/hash/01b7575c38dac42f3cfb7d500438b875-Abstract.html) | Muhammad Anas Tahir |
| June 20, 2023 | Parameter Efficiency - Prompt Tuning | [Transitional adaptation of pretrained models for visual storytelling](https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Transitional_Adaptation_of_Pretrained_Models_for_Visual_Storytelling_CVPR_2021_paper.html) | Mahnoor Shahid            |
| June 20, 2023 | Parameter Efficiency - Prefix-Tuning | [Hyperpelt: Unified parameter-efficient language model tuning for both language and vision-and-language tasks](https://arxiv.org/abs/2203.03878) | Sijie Wu                  |
| June 27, 2023 | Parameter Efficiency - Prefix-Tuning | [Visual Prompt Tuning](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136930696.pdf) | Prathvish Mithare?        |
| June 27, 2023 | Parameter Efficiency - Adapters      | [Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks](https://openaccess.thecvf.com/content/CVPR2022/html/Sung_VL-Adapter_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Tasks_CVPR_2022_paper.html) | Muhammed Saeed            |
| July 4, 2023  | Parameter Efficiency - Adapters      | [LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning](https://openreview.net/forum?id=isPnnaTZaP5) | Rajkumar Anilkumar Vaghashiya |
| July 4, 2023 | Generative Model - Text-to-Image     | [High-resolution image synthesis with latent diffusion models](https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html) | Shreyash Arya             |
| July 11, 2023 | Generative Model - GPT               | [GPT-4](https://openai.com/research/gpt-4), [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774) | Abdul Rafay               |
| July 11, 2023 | Generative Model - GPT               | [Visual ChatGPT: Talking, Drawing, and Editing with Visual Foundation Models](https://arxiv.org/abs/2303.04671) | Huseyin Alecakir         |
| July 18, 2023 | Reinforcement Learning              | [No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling](https://aclanthology.org/P18-1083/) | ?                         |
| July 18, 2023 | Reinforcement Learning              | [What Makes a Good Story? Designing Composite Rewards for Visual Storytelling](https://ojs.aaai.org/index.php/AAAI/article/view/6305) | Ruveyda Betül Bahçeci     |


## Introduction

Please find it [here](http://xudonghong.me/mllv-uds/intro). 

## Topics

Please find them [here](http://xudonghong.me/mllv-uds/topic). 

## Grading
- 10% draft presentation (due each Wednesday)
- 10% questions about the papers (due each Friday)
- 35% final talk
- 5% Attendance of all the talks and giving feedbacks
- 5% Discussion during the talk with the others
- 35% Term paper
- (optional) 10% Demo

## Representations

1. [Kickoff Meeting](./Seminar ML for Language and Vision_kickoff.pdf)
2. [Introduction Meeting](./Seminar ML for Language and Vision_introduction.pdf)

## Requirement

Students should have a basic understanding of deep learning, natural language processing and computer vision concepts. Students are expected to actively engage in discussions and critically analyze the papers presented during the seminar. They are also encouraged to share their own insights and perspectives on the topics covered.

## Discussion Format

We will have a group discussion on each paper, where participants need to first present the papers. Then others can share their thoughts and insights on the research.

## Date and Time

every Tue 12:15-13:45

kick-off meeting on Apr 18, 2023
Location: Gebäude C7 3 - Seminarraum 1.12

## Contact

If you have any questions or concerns, please contact us via email. We look forward to seeing you at the discussion!

**Xudong Hong**: [xhong@coli.uni-saarland.de](mailto:xhong@coli.uni-saarland.de)

**Ruitao Feng**: [fruitao@coli.uni-saarland.de](mailto:fruitao@coli.uni-saarland.de)

## (The following is under construction. Please stay tuned. )
